{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d596d455",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import numpy as np\n",
    "import scipy\n",
    "import itertools\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.distance import cdist\n",
    "from collections import Counter\n",
    "from random import choice\n",
    "\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7b9aa4e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data\n",
    "train_matrix = [] # Forming a 2D matrix to store all training feature vectors\n",
    "\n",
    "#Test Data\n",
    "test_matrix = [] # Forming a 2D matrix to store all test feature vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd725265",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained = pd.read_csv('C:/Rafat/SEDM/II2202/Data/Train_Clean.csv')#, nrows=20000\n",
    "test = pd.read_csv('C:/Rafat/SEDM/II2202/Data/Test_Clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e5ef776d",
   "metadata": {},
   "outputs": [],
   "source": [
    "trained['Lemmatized'].replace('', np.nan, inplace=True)\n",
    "trained.dropna(subset=['Lemmatized'], inplace=True)\n",
    "\n",
    "test['Lemmatized'].replace('', np.nan, inplace=True)\n",
    "test.dropna(subset=['Lemmatized'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9b00e18",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_unique = (list(set(trained['Lemmatized'].str.findall(\"\\w+\").sum()))) # Finding all the unique words in training data's Tweet column\n",
    "train_unique_words = len(train_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "030a117b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Training Data: Extracting features and storing them into the training feature matrix\n",
    "for sentence in trained['Lemmatized']:\n",
    "    train_featurevec = []\n",
    "    word = sentence.split()\n",
    "    for w in train_unique:\n",
    "        train_featurevec.append(word.count(w))\n",
    "    train_matrix.append(train_featurevec)\n",
    "\n",
    "#Test Data: Extracting features and storing them into the test feature matrix\n",
    "for sentence in test['Lemmatized']:\n",
    "    test_featurevec = []\n",
    "    word = sentence.split()\n",
    "    for w in train_unique:\n",
    "        test_featurevec.append(word.count(w))\n",
    "    test_matrix.append(test_featurevec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "dba90719",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\rafat\\anaconda3\\lib\\site-packages\\xgboost\\sklearn.py:1224: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[18:20:45] WARNING: C:\\Windows\\Temp\\abs_557yfx631l\\croots\\recipe\\xgboost-split_1659548953302\\work\\src\\learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "\n",
      "\n",
      "Confusion Matrix:\n",
      "[[333   7 108  36  24]\n",
      " [  9 346  25  32 125]\n",
      " [ 53  20 542 158 149]\n",
      " [  2   4  62 445  58]\n",
      " [ 19  45 112 144 595]]\n",
      "Accuracy Score is: 65.0%\n",
      "Macroaveraged Recall is: 66.0%\n",
      "Macroaveraged Precision is: 69.0%\n",
      "Macroaveraged F1-score 67.0%\n"
     ]
    }
   ],
   "source": [
    "acc_list = []\n",
    "rec_list = []\n",
    "prec_list = []\n",
    "f1_list = []\n",
    "\n",
    "trainfeatures = train_matrix\n",
    "testfeatures = test_matrix\n",
    "X_train = trainfeatures #train_matrix - 2D feature vector\n",
    "X_test = testfeatures #test_matrix - 2D feature vector\n",
    "y_train = trained['Sentiment'] #trained['Sentiment]\n",
    "y_test = test['Sentiment'] #test['Sentiment]\n",
    "\n",
    "classifier = XGBClassifier()\n",
    "classifier.fit(X_train, y_train) #Fitting the built-in sklearn classifier on our training data\n",
    "predicted_label = classifier.predict(X_test) #Making the classifier to predict on the previously unseen test data.\n",
    "accuracy_score = (metrics.accuracy_score(y_test,predicted_label))\n",
    "accuracy_score = (round(accuracy_score,2))*100\n",
    "acc_list.append(accuracy_score)\n",
    "\n",
    "confusion_mat = confusion_matrix(y_test, predicted_label)\n",
    "class_report = classification_report(y_test, predicted_label)\n",
    "\n",
    "macro_precision = (metrics.precision_score(y_test, predicted_label, average='macro'))\n",
    "macro_precision = (round(macro_precision,2))*100\n",
    "prec_list.append(macro_precision)\n",
    "\n",
    "macro_recall = (metrics.recall_score(y_test, predicted_label, average='macro'))\n",
    "macro_recall = (round(macro_recall,2))*100\n",
    "rec_list.append(macro_recall)\n",
    "    \n",
    "macro_f1 = (metrics.f1_score(y_test, predicted_label, average='macro'))\n",
    "macro_f1 = (round(macro_f1,2))*100\n",
    "f1_list.append(macro_f1)\n",
    "\n",
    "print(\"\\n\\nConfusion Matrix:\")\n",
    "print(confusion_mat)\n",
    "#print(\"\\nClassification Report for k = {} is:\\n\".format(k))\n",
    "#print(class_report)\n",
    "print(\"Accuracy Score is: {0}%\".format(accuracy_score))\n",
    "print(\"Macroaveraged Recall is: {0}%\".format(macro_recall))\n",
    "print(\"Macroaveraged Precision is: {0}%\".format(macro_precision))\n",
    "print(\"Macroaveraged F1-score {0}%\".format(macro_f1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa0c14f7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
